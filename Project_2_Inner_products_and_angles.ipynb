{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mabinogit/AI-Image-Classification/blob/main/Project_2_Inner_products_and_angles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szNRzFwtHt3D"
      },
      "source": [
        "Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPyB5-zxGIfX"
      },
      "source": [
        "# Inner Products and Angles\n",
        "\n",
        "Build a document similarity system using TF - IDF vectorization and cosine similarity to compare text documents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c92c84fc"
      },
      "source": [
        "# Task\n",
        "Load the data from the file \"/content/reuters21578.tar.gz\", then display the first 5 rows, the columns and their types."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d35cbac8"
      },
      "source": [
        "## Extract the data\n",
        "\n",
        "### Subtask:\n",
        "Extract the files from the `.tar.gz` archive.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "753bf63b"
      },
      "source": [
        "**Reasoning**:\n",
        "Extract the files from the tar.gz archive using the tarfile library.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8afb1b79"
      },
      "outputs": [],
      "source": [
        "import tarfile\n",
        "\n",
        "with tarfile.open(\"/content/reuters21578.tar.gz\", \"r:gz\") as tar:\n",
        "    tar.extractall()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1afcc57a"
      },
      "source": [
        "## Identify data files\n",
        "\n",
        "### Subtask:\n",
        "Examine the extracted files to understand their structure and identify the relevant data files.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65e7afc3"
      },
      "source": [
        "**Reasoning**:\n",
        "List the extracted files and directories to understand the file structure and identify potential data files.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76b810dd",
        "outputId": "75914a42-8019-4397-e8e9-4bd294acb7ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['.config', 'all-people-strings.lc.txt', 'reut2-010.sgm', 'all-places-strings.lc.txt', 'all-orgs-strings.lc.txt', 'reut2-006.sgm', 'reut2-016.sgm', 'reut2-015.sgm', 'reut2-004.sgm', 'all-exchanges-strings.lc.txt', 'reut2-007.sgm', 'reut2-008.sgm', 'reut2-001.sgm', 'reut2-013.sgm', 'reut2-017.sgm', 'all-topics-strings.lc.txt', 'reut2-019.sgm', 'reut2-009.sgm', 'cat-descriptions_120396.txt', 'reut2-020.sgm', 'reut2-002.sgm', 'reut2-000.sgm', 'reut2-003.sgm', 'reut2-005.sgm', 'feldman-cia-worldfactbook-data.txt', 'README.txt', 'reut2-012.sgm', 'lewis.dtd', 'reut2-014.sgm', 'reut2-021.sgm', 'reuters21578.tar.gz', 'reut2-011.sgm', 'reut2-018.sgm', 'sample_data']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "extracted_files = os.listdir('.')\n",
        "print(extracted_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6817464b"
      },
      "source": [
        "**Reasoning**:\n",
        "The file listing shows several files with the '.sgm' extension (e.g., 'reut2-000.sgm', 'reut2-001.sgm', etc.). These are likely the main data files containing the text documents. I will use the `head` command to peek into one of these files to confirm its content structure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fff84b2",
        "outputId": "8c748029-c250-4e16-fe0e-aebb9133db0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<!DOCTYPE lewis SYSTEM \"lewis.dtd\">\n",
            "<REUTERS TOPICS=\"YES\" LEWISSPLIT=\"TRAIN\" CGISPLIT=\"TRAINING-SET\" OLDID=\"5544\" NEWID=\"1\">\n",
            "<DATE>26-FEB-1987 15:01:01.79</DATE>\n",
            "<TOPICS><D>cocoa</D></TOPICS>\n",
            "<PLACES><D>el-salvador</D><D>usa</D><D>uruguay</D></PLACES>\n",
            "<PEOPLE></PEOPLE>\n",
            "<ORGS></ORGS>\n",
            "<EXCHANGES></EXCHANGES>\n",
            "<COMPANIES></COMPANIES>\n",
            "<UNKNOWN> \n"
          ]
        }
      ],
      "source": [
        "!head reut2-000.sgm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "195a1263"
      },
      "source": [
        "## Load data\n",
        "\n",
        "### Subtask:\n",
        "Load the data from the relevant files into a suitable data structure (e.g., pandas DataFrame).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77b9ddcc"
      },
      "source": [
        "**Reasoning**:\n",
        "Import necessary libraries and define a function to parse the SGM files and extract relevant data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96e55f58"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def parse_sgm(file_path):\n",
        "    with open(file_path, 'r', encoding='latin-1') as f:\n",
        "        content = f.read()\n",
        "\n",
        "    # Split the file content by the <REUTERS> tag to get individual documents\n",
        "    docs = content.split('</REUTERS>')\n",
        "\n",
        "    parsed_data = []\n",
        "    for doc in docs:\n",
        "        if '<REUTERS' not in doc:\n",
        "            continue\n",
        "\n",
        "        # Extract relevant information using regex\n",
        "        title_match = re.search(r'<TITLE>(.*?)</TITLE>', doc, re.DOTALL)\n",
        "        body_match = re.search(r'<BODY>(.*?)</BODY>', doc, re.DOTALL)\n",
        "        topics_match = re.search(r'<TOPICS>(.*?)</TOPICS>', doc, re.DOTALL)\n",
        "\n",
        "        title = title_match.group(1).strip() if title_match else None\n",
        "        body = body_match.group(1).strip() if body_match else None\n",
        "        topics = []\n",
        "        if topics_match:\n",
        "            topic_list = re.findall(r'<D>(.*?)</D>', topics_match.group(1))\n",
        "            topics = topic_list\n",
        "\n",
        "        if body: # Only include documents with a body\n",
        "            parsed_data.append({\n",
        "                'title': title,\n",
        "                'body': body,\n",
        "                'topics': topics\n",
        "            })\n",
        "    return parsed_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00942f4a"
      },
      "source": [
        "**Reasoning**:\n",
        "Iterate through all SGM files, parse them, collect the data, and convert it into a pandas DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a09ae43e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "sgm_files = [f for f in os.listdir('.') if f.endswith('.sgm')]\n",
        "\n",
        "all_docs_data = []\n",
        "for sgm_file in sgm_files:\n",
        "    file_path = os.path.join('.', sgm_file)\n",
        "    all_docs_data.extend(parse_sgm(file_path))\n",
        "\n",
        "df = pd.DataFrame(all_docs_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "051ed43f"
      },
      "source": [
        "## Inspect data\n",
        "\n",
        "### Subtask:\n",
        "Display the first few rows and the columns and their types to get an initial understanding of the data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "838ed70f"
      },
      "source": [
        "**Reasoning**:\n",
        "Display the first few rows and the columns and their types to get an initial understanding of the data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "8434da24",
        "outputId": "33cdaf4b-eff8-43a9-b57d-8b3c515f7f4b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"ISLAND TELEPHONE SHARE SPLIT APPROVED\",\n          \"U.K. GROWING IMPATIENT WITH JAPAN - THATCHER\",\n          \"BIOGEN &lt;BGNF> GETS PATENT FROM EUROPEAN OFFICE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"body\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"&lt;Island\\nTelephone Co Ltd> said the previously announced two-for-one\\ncommon share split was approved by shareholders at the annual\\nmeeting.\\n Reuter\\n&#3;\",\n          \"Prime Minister Margaret Thatcher said\\nthe U.K. Was growing more impatient with Japanese trade\\nbarriers and warned that it would soon have new powers against\\ncountries not offering reciprocal access to their markets.\\n    She told Parliament that the bid by the U.K.'s Cable and\\nWireless Plc &lt;CAWL.L> to enter the Japanese telecommunications\\nmarket was being regarded by her government as a test case.\\n    \\\"I wrote to the prime minister of Japan, Mr Nakasone, on the\\nfourth of March to express our interest on the Cable and\\nWireless bid. I have not yet had a reply. We see this as a test\\non how open the Japanese market really is,\\\" Thatcher said.\\n    Thatcher told Parliament that \\\"shortly ... We shall have\\nmore powers than we have now, when, for example the powers\\nunder the Financial Services Act and the Banking Act become\\navailable, then we shall be able to take action in cases where\\nother countries do not offer the same full access to financial\\nservices as we do.\\\"\\n    Cable and Wireless is seeking a stake in the proposed\\nJapanese telecommunications rival to Kokusai Denshin Denwa.\\n    But the Japanese minister for post and telecommunications\\nwas reported as saying that he opposed Cable and Wireless\\nhaving a managerial role in the new company.\\n REUTER\\n&#3;\",\n          \"Biogen Inc said the European\\nPatent Office granted it a patent covering certain proteins\\nused to produce a hepatitis B vaccine through genetic\\nengineering techniques.\\n    Robert Gottlieb, Biogen spokesman, said the company has\\nlicensed the vaccine on a nonexclusive basis to &lt;Wellcome PLC>,\\nthe British pharmaceutical firm, and is discussing licensing\\nwith other companies.\\n    Biogen said the patent gives it the right to exclude others\\nfrom marketing hepatitis B vaccine in the 11 member countries\\nof the European Patent Convention.\\n    Gottlieb said the company has also filed a patent in other\\nmarkets, including the U.S. The vaccine is in clinical tests.\\n    Patents in the biotechnology field are particularly\\nimportant as the company with an exclusive patent can reap\\nlarge rewards. Recently many of the products of genetic\\nengineering have become the target of patent lawsuits.\\n    Merck and Co Inc &lt;MRK> already sells a genetically\\nengineered hepatitis B vaccine in the U.S. called Recombivax\\nHB. A subsidiary of &lt;SmithKline Beckman Corp>, SmithKline\\nBiologicals, based in Belgium, is selling a hepatitis B\\nvaccine, called Engerix-B, in Belgium.\\n    A SmithKline spokesman said the vaccine has also been\\nformally approved in Switzerland and Luxembourg and has been\\nauthorized for market in a number of Far East countries.\\n    Hepatitis B is a serious liver infection common in many\\nparts of Africa and southeast Asia where about five pct to 15\\npct of the population carry the virus. In the U.S. about\\n200,000 new cases occur each year.\\n    Last December the European Patent Ofice rejected Biogen's\\npatent for alpha-interferon, which Biogen said it will appeal\\nonce it receives a formal written opinion from the office.\\n   \\n Reuter\\n&#3;\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topics\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-e8368584-1754-433a-8408-a6f5bd058638\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>body</th>\n",
              "      <th>topics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AMOCO &amp;lt;AN&gt; UNIT EXPANDS CARPET YARN PLANT</td>\n",
              "      <td>Amoco Corp said its Amoco Fabrics Co\\nwill exp...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ISLAND TELEPHONE SHARE SPLIT APPROVED</td>\n",
              "      <td>&amp;lt;Island\\nTelephone Co Ltd&gt; said the previou...</td>\n",
              "      <td>[earn]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BIOGEN &amp;lt;BGNF&gt; GETS PATENT FROM EUROPEAN OFFICE</td>\n",
              "      <td>Biogen Inc said the European\\nPatent Office gr...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>KEY U.S. HOUSE MEMBER OPPOSES CFTC USER PLAN</td>\n",
              "      <td>A key U.S. House member said he\\nopposed a Rea...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>U.K. GROWING IMPATIENT WITH JAPAN - THATCHER</td>\n",
              "      <td>Prime Minister Margaret Thatcher said\\nthe U.K...</td>\n",
              "      <td>[trade, acq]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8368584-1754-433a-8408-a6f5bd058638')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e8368584-1754-433a-8408-a6f5bd058638 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e8368584-1754-433a-8408-a6f5bd058638');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5f329632-5f72-44b7-b14c-4027f17cca9b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5f329632-5f72-44b7-b14c-4027f17cca9b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5f329632-5f72-44b7-b14c-4027f17cca9b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                               title  \\\n",
              "0       AMOCO &lt;AN> UNIT EXPANDS CARPET YARN PLANT   \n",
              "1              ISLAND TELEPHONE SHARE SPLIT APPROVED   \n",
              "2  BIOGEN &lt;BGNF> GETS PATENT FROM EUROPEAN OFFICE   \n",
              "3       KEY U.S. HOUSE MEMBER OPPOSES CFTC USER PLAN   \n",
              "4       U.K. GROWING IMPATIENT WITH JAPAN - THATCHER   \n",
              "\n",
              "                                                body        topics  \n",
              "0  Amoco Corp said its Amoco Fabrics Co\\nwill exp...            []  \n",
              "1  &lt;Island\\nTelephone Co Ltd> said the previou...        [earn]  \n",
              "2  Biogen Inc said the European\\nPatent Office gr...            []  \n",
              "3  A key U.S. House member said he\\nopposed a Rea...            []  \n",
              "4  Prime Minister Margaret Thatcher said\\nthe U.K...  [trade, acq]  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 19043 entries, 0 to 19042\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   title   19043 non-null  object\n",
            " 1   body    19043 non-null  object\n",
            " 2   topics  19043 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 446.4+ KB\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(df.head())\n",
        "display(df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqYlS3QjXm_d"
      },
      "source": [
        "# Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "bf07158d"
      },
      "outputs": [],
      "source": [
        "text1 = \"Hello my name is christian km\"\n",
        "text2 = \"Hello my name is christian mmbk \"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U27Ig0S5duXy"
      },
      "source": [
        "global dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7QghDrcPH8J"
      },
      "outputs": [],
      "source": [
        "def dic(docs):\n",
        "  stopwords = [\"the\"]\n",
        "\n",
        "# Initialize the words list outside the loop\n",
        "  all_words = []\n",
        "\n",
        "  for doc in docs:\n",
        "  # Get words from the current document, convert to lowercase and split\n",
        "    doc_words = doc.lower().split()\n",
        "  # Extend the all_words list with words from the current document\n",
        "    all_words.extend(doc_words)\n",
        "\n",
        "# Remove stopwords from the collected words\n",
        "  filtered_words = [word for word in all_words if word not in stopwords]\n",
        "  vec_dictionary = tuple(sorted(set(filtered_words)))\n",
        "\n",
        "  return vec_dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oWRNF_7Yfak",
        "outputId": "26dd5cd8-ebe7-41a7-9074-fdce11fe6267"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('christian', 'hello', 'is', 'km', 'mmbk', 'my', 'name')\n"
          ]
        }
      ],
      "source": [
        "docs = [text1, text2]\n",
        "vec_dictionary = dic(docs)\n",
        "print(vec_dictionary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4dpKSTTd68a"
      },
      "source": [
        "# IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ROadO34a1GH"
      },
      "outputs": [],
      "source": [
        "# N - Total number of documents\n",
        "# df - Number of documents containing the term\n",
        "import math\n",
        "\n",
        "def idf_calc(df, docs):\n",
        "    \"\"\"Calculates the Inverse Document Frequency (IDF) for a term.\"\"\"\n",
        "    N = len(docs)\n",
        "    idf = {}\n",
        "    for word in df:\n",
        "      df_val = df[word]\n",
        "\n",
        "      idf_val = math.log((N + 1) / (df_val + 1)) + 1\n",
        "\n",
        "\n",
        "      idf[word] = idf_val\n",
        "    return idf\n",
        "def calculate_document_frequency(vec_dictionary, docs):\n",
        "    \"\"\"Calculates the document frequency for each word in a list of documents.\"\"\"\n",
        "    df = {}\n",
        "    for word in vec_dictionary:\n",
        "      for doc in docs:\n",
        "        if word in doc:\n",
        "          if word in df:\n",
        "            df[word] += 1\n",
        "          else:\n",
        "            df[word] = 1\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ky4XKeyya_jD",
        "outputId": "64a6cdf1-d048-41e9-88c5-99b6b4805445"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'christian': 2, 'is': 2, 'km': 1, 'mmbk': 1, 'my': 2, 'name': 2}\n"
          ]
        }
      ],
      "source": [
        "freq = calculate_document_frequency(vec_dictionary, docs)\n",
        "print(freq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cU3SaYykbmX3",
        "outputId": "4e1023d2-09c5-40e0-fe04-568fad489d40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'christian': 1.0, 'is': 1.0, 'km': 1.4054651081081644, 'mmbk': 1.4054651081081644, 'my': 1.0, 'name': 1.0}\n"
          ]
        }
      ],
      "source": [
        "idf = idf_calc(freq, docs)\n",
        "print(idf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "fvHpaUuYP5E4"
      },
      "outputs": [],
      "source": [
        "def tf(text):\n",
        "\n",
        "  stopwords = [\"the\"]\n",
        "\n",
        "# Initialize the words list outside the loop\n",
        "  all_words = []\n",
        "\n",
        "  for word in text:\n",
        "  # Get words from the current document, convert to lowercase and split\n",
        "    doc_words = text.lower().split()\n",
        "  # Extend the all_words list with words from the current document\n",
        "    all_words.extend(doc_words)\n",
        "\n",
        "# Remove stopwords from the collected words\n",
        "  filtered_words = [word for word in all_words if word not in stopwords]\n",
        "\n",
        "\n",
        "  # Initialize word_val and vectors (can be used for TF calculation later)\n",
        "  word_val = {}\n",
        "  vectors = []\n",
        "  sum = 0\n",
        "\n",
        "\n",
        "# Iterate through the words and count their occurrences\n",
        "  for word in filtered_words:\n",
        "    if word in word_val:\n",
        "      word_val[word] += 1\n",
        "    else:\n",
        "      word_val[word] = 1\n",
        "\n",
        "\n",
        "  for word in word_val:\n",
        "    sum += word_val[word]\n",
        "\n",
        "\n",
        "  for word in word_val:\n",
        "    word_val[word] = word_val[word] / sum\n",
        "\n",
        "  return word_val\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf_text1 = tf(text1)\n",
        "print(tf_text1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvBqjVb2tE8Z",
        "outputId": "c66868b9-9fcd-4e9b-cdf2-d084861fa8ab"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'hello': 0.1111111111111111, 'my': 0.1111111111111111, 'name': 0.1111111111111111, 'is': 0.1111111111111111, 'christian': 0.1111111111111111, 'n': 0.1111111111111111, 'joejen': 0.1111111111111111, 'kjnkjno': 0.1111111111111111, 'kjnknvs': 0.1111111111111111}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsjaE_BWceNu"
      },
      "source": [
        "# IF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eg7Ogrmxcg97"
      },
      "outputs": [],
      "source": [
        "def tf_idf(tf, idf, dictionary):\n",
        "  \"\"\"Calculates the TF-IDF value for terms based on their TF and IDF values.\"\"\"\n",
        "  tfidf_values = {}\n",
        "\n",
        "  for word, tf_value in tf.items():\n",
        "    if word in idf:\n",
        "\n",
        "      tfidf_values[word] = tf_value * idf[word]\n",
        "    else:\n",
        "      # Handle cases where a word in TF is not in IDF (shouldn't happen if both are from the same corpus)\n",
        "      tfidf_values[word] = tf_value * 0 # Or handle as appropriate, e.g., raise an error or log a warning\n",
        "\n",
        "  vector = []\n",
        "  for word in dictionary:\n",
        "      if word in tfidf_values:\n",
        "          vector.append(tfidf_values[word])\n",
        "      else:\n",
        "          vector.append(0) # Append 0 if the word is not in tfidf_values\n",
        "\n",
        "  return tfidf_values, vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xR925EXfqqe",
        "outputId": "c5bf6053-411e-49ee-bab3-af39d5f5ee9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'hello': 0.0, 'my': 0.18181818181818182, 'name': 0.18181818181818182, 'is': 0.18181818181818182, 'christian': 0.18181818181818182, 'x': 0.1277695552825604}\n",
            "[0.18181818181818182, 0.0, 0.18181818181818182, 0.18181818181818182, 0.18181818181818182, 0.1277695552825604]\n"
          ]
        }
      ],
      "source": [
        "tf_idf_text1 , vector1 = tf_idf(tf_text1, idf, vec_dictionary )\n",
        "print(tf_idf_text1)\n",
        "print(vector1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVQ8ocOVKl3u",
        "outputId": "4655606a-8d3f-4bc1-eb13-7f6acff87046"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'hello': 0.0, 'my': 0.18181818181818182, 'name': 0.18181818181818182, 'is': 0.18181818181818182, 'christian': 0.18181818181818182, 'x': 0.1277695552825604}\n",
            "[0.18181818181818182, 0.0, 0.18181818181818182, 0.18181818181818182, 0.18181818181818182, 0.1277695552825604]\n"
          ]
        }
      ],
      "source": [
        "tf_idf_text2 , vector2 = tf_idf(tf_text2, idf, vec_dictionary )\n",
        "print(tf_idf_text2)\n",
        "print(vector2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCy4L82WKj0I"
      },
      "source": [
        "## Cosine Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "HCDgG6hVEJS9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine(vector1, vector2):\n",
        "  \"\"\"Calculates the cosine similarity between two vectors.\"\"\"\n",
        "  vector1 = np.array(vector1)\n",
        "\n",
        "  vector2 = np.array(vector2)\n",
        "\n",
        "  cosine = (vector1 @ vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
        "  return cosine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdBBgeFQLCAk"
      },
      "source": [
        "# Cosine similarity - TF_IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DU9dceQ8LJrZ",
        "outputId": "e997ef0e-7aa1-48b5-b501-06e3f8053e2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.18181818 0.         0.18181818 0.18181818 0.18181818 0.12776956]\n",
            "[0.18181818 0.         0.18181818 0.18181818 0.18181818 0.12776956]\n",
            "0.9999999999999998\n",
            "The documents are similar\n"
          ]
        }
      ],
      "source": [
        "similarity = cosine(vector1, vector2)\n",
        "print(similarity)\n",
        "\n",
        "if similarity > 0.5:\n",
        "  print(\"The documents are similar\")\n",
        "else:\n",
        "  print(\"The documents are not similar\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8pAA7mefCZp"
      },
      "source": [
        "# System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "elFtUB2_fXow"
      },
      "outputs": [],
      "source": [
        "def similarity_system(doc, text_1, texts_2 ):\n",
        "  vec_dictionary = dic(doc)\n",
        "\n",
        "\n",
        "\n",
        "  freq = calculate_document_frequency(vec_dictionary, doc)\n",
        "\n",
        "\n",
        "  idf = idf_calc(freq, doc)\n",
        "\n",
        "\n",
        "  tf_text1 = tf(text_1)\n",
        "\n",
        "  tf_text2 = tf(texts_2)\n",
        "\n",
        "\n",
        "  tf_idf_text1 , vector1 = tf_idf(tf_text1, idf, vec_dictionary )\n",
        "\n",
        "\n",
        "  tf_idf_text2 , vector2 = tf_idf(tf_text2, idf, vec_dictionary )\n",
        "\n",
        "\n",
        "  similarity = cosine(vector1, vector2)\n",
        "  print(similarity)\n",
        "  if similarity > 0.5:\n",
        "    print(\"The documents are similar\")\n",
        "  else:\n",
        "    print(\"The documents are not similar\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test on Corpus"
      ],
      "metadata": {
        "id": "r-5cegqpvY55"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETIyYRiVfpmW",
        "outputId": "e3af411a-0056-4e45-cba7-7e57a9c8624f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "The documents are not similar\n"
          ]
        }
      ],
      "source": [
        "text1 = \"and you me\"\n",
        "text2 = \"how about we rule\"\n",
        "\n",
        "docx = [text1, text2]\n",
        "similarity_system(docx, text1, text2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfIGln8Efsxj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee7e13ef"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def parse_sgm(file_path):\n",
        "    with open(file_path, 'r', encoding='latin-1') as f:\n",
        "        content = f.read()\n",
        "\n",
        "    # Split the file content by the <REUTERS> tag to get individual documents\n",
        "    docs = content.split('</REUTERS>')\n",
        "\n",
        "    parsed_data = []\n",
        "    for doc in docs:\n",
        "        if '<REUTERS' not in doc:\n",
        "            continue\n",
        "\n",
        "        # Extract relevant information using regex\n",
        "        title_match = re.search(r'<TITLE>(.*?)</TITLE>', doc, re.DOTALL)\n",
        "        body_match = re.search(r'<BODY>(.*?)</BODY>', doc, re.DOTALL)\n",
        "        topics_match = re.search(r'<TOPICS>(.*?)</TOPICS>', doc, re.DOTALL)\n",
        "\n",
        "        title = title_match.group(1).strip() if title_match else None\n",
        "        body = body_match.group(1).strip() if body_match else None\n",
        "        topics = []\n",
        "        if topics_match:\n",
        "            topic_list = re.findall(r'<D>(.*?)</D>', topics_match.group(1))\n",
        "            topics = topic_list\n",
        "\n",
        "        if body: # Only include documents with a body\n",
        "            parsed_data.append({\n",
        "                'title': title,\n",
        "                'body': body,\n",
        "                'topics': topics\n",
        "            })\n",
        "    return parsed_data\n",
        "\n",
        "sgm_files = [f for f in os.listdir('.') if f.endswith('.sgm')]\n",
        "\n",
        "all_docs_data = []\n",
        "for sgm_file in sgm_files:\n",
        "    file_path = os.path.join('.', sgm_file)\n",
        "    all_docs_data.extend(parse_sgm(file_path))\n",
        "\n",
        "# Extract the 'body' of the documents for similarity testing\n",
        "doc_texts = [doc['body'] for doc in all_docs_data if doc['body']]"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Test similarity between the first two documents\n",
        "if len(doc_texts) >= 2:\n",
        "    text1 = doc_texts[0]\n",
        "    text2 = doc_texts[1]\n",
        "    print(f\"Calculating similarity between document 1 and document 2:\")\n",
        "    similarity_system(doc_texts, text1, text2)\n",
        "elif len(doc_texts) == 1:\n",
        "    print(\"Only one document found. Cannot calculate similarity between two documents.\")\n",
        "else:\n",
        "    print(\"No documents with body found in the SGM files.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iLVuU1xwxSp",
        "outputId": "5babb4f9-3f02-408a-f54e-d6280a01fa3c"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating similarity between document 1 and document 2:\n",
            "0.053568768973858275\n",
            "The documents are not similar\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPoeU8bh6t0j5rmf+BL6ePu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}